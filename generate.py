"""This file defines the class NgramModel. It accepts a list of tokenized sentences (in the form generated by CorpusReader.sents()).
It removes punctuation tokens, converts all words to lower case, adds 1 sentence-end token (</s>) at the end of each sentence, adds n-1 sentence-start tokens (<s>) 
at the beginning of each sentence. It Uses the result to pre-calculate and store the frequency tables needed by the methods listed below.
Store the frequency tables in a variable inside the class."""
# Note: Do not concatenate the sentences back into one long string; these ngrams are calculated on sentences, not across sentence boundaries.
# A frequency table stores the raw counts of the ngrams (e.g. for trigrams, if "the cat" is followed by "slept" 7 times, there should be a 7 in there.
# This encodes how many time a prefix of words of length n-1 was followed by a word
# dictionaries are efficient for storing this kind of information, but you can do it any way you like as long as it doesn’t take forever to build or use
# Note that lists are unhashable, so if you use a dictionary, you’ll need to make the keys something else (e.g. tuples of the first n-1 words, or you can re-concatenate them with a safe delimiter).
# You will probably want additional things stored in your model. It’s up to you to figure out what you need!
# While your modules and classes can have additional functions, variables, etc. defined, they must also work exactly as specified in the assignment. For example, no adding new parameters to functions (unless you give them a default value), no choosing different names for functions, etc.)
# Try to avoid storing the raw dataset itself in the model. It makes it very a large object, and once you build your model, it’s redundant

# TODO

#TODO comment pretty
#%%
import re
from corpusreader import CorpusReader
import random

class NgramModel:
    """Accepts a list of tokenized sentences in the form generated by CorpusReader.sents()"""
    def __init__(self,tokenizedsentences):
        self.tokenizedsentences=tokenizedsentences
        #creates a copy of the tokenized list to avoid change of original data
        copyoftokenizedsentences=tokenizedsentences.copy()
        newsentences=[]
        for sentence in copyoftokenizedsentences:
            for  word in sentence:
                #if word is not only composed of punctuation, removes it from the list
                if re.match('\W+',word):
                    sentence.remove(word)    
            #converts all to lowercase
            sentence = [word.lower() for word in sentence]
                #adds 1 sentence-end token (</s>) at the end of each sentence
            sentence.append('</s>')
             #adds n-1 sentence-start tokens (<s>) at the beginning of each sentence,
            sentence.insert(0,'<s>')
            newsentences.append(sentence)
            #store the frequency tables in a variable inside the class.
        self.sentences= newsentences     
            
       
       
       
       
corpus = CorpusReader("C:/Users/ritav/OneDrive - Universiteit Utrecht/A computational linguistics/train")
sentences = corpus.sents()  # a list of lists of tokens
test=NgramModel(sentences)
print(test.sentences)
