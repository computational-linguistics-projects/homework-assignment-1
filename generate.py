"""This file defines the class NgramModel. It accepts a list of tokenized sentences (in the form generated by CorpusReader.sents()).
It removes punctuation tokens, converts all words to lower case, adds 1 sentence-end token (</s>) at the end of each sentence, adds n-1 sentence-start tokens (<s>) 
at the beginning of each sentence. It Uses the result to pre-calculate and store the frequency tables needed by the methods listed below.
Store the frequency tables in a variable inside the class."""

#TODO comment pretty

#%%
import re
from corpusreader import CorpusReader
import random

class NgramModel:
    """Accepts a list of tokenized sentences in the form generated by CorpusReader.sents()"""
    def __init__(self,tokenizedsentences,ngramcount):
        self.tokenizedsentences=tokenizedsentences
        self.ngramcount=ngramcount
        #creates a copy of the tokenized list to avoid change of original data
        self.cleandata= self.cleaningdata()     
        #calling the function from within the initializer, to keep cleaner code
        self.frequency=self.frequencytables()
        #self.probability=self.probability(self.frequency)
        
    def cleaningdata(self):
        copyoftokenizedsentences=self.tokenizedsentences.copy()
        newsentences=[]
        for sentence in copyoftokenizedsentences:
            for  word in sentence:
                #if word is not only composed of punctuation, removes it from the list
                if re.match('\W+',word):
                    sentence.remove(word)    
            #converts all to lowercase
            sentence = [word.lower() for word in sentence]
                #adds 1 sentence-end token (</s>) at the end of each sentence
            sentence.append('</s>')
             #adds n-1 sentence-start tokens (<s>) at the beginning of each sentence,
            sentence.insert(0,'<s>')
            newsentences.append(sentence)
        return newsentences     
        
        
    def frequencytables(self):
        ngramlist=[]
        for sentence in self.cleandata:
            x=0
            y=self.ngramcount
            while y<len(sentence)-1:
                ngramlist.append(tuple(sentence[x:y]))
                x+=1
                y+=1    
        frequencytable={}      
        for ngram in ngramlist:
            if ngram in frequencytable:
                frequencytable[ngram]+=1
            else:
                frequencytable[ngram]=1        
        return frequencytable             
    
    def probability(self,ngram,smoothing_constant=0.0):
        #sum of the counts of each ngram that share the same prefix
        sumofprefixcounts=0
        #sum of ngrams that share the same prefix
        sumofprefix=0
        currentdictionary=self.frequency
        if ngram in currentdictionary.keys():
            for key in currentdictionary.keys():
                if key[0]==ngram[0]:
                    sumofprefixcounts+=currentdictionary[ngram]
                    sumofprefix+=1
            if smoothing_constant==0.0:
                rawprobability= self.frequency[ngram]/sumofprefixcounts
                return rawprobability
            else:
                ksmoothedprobability= (self.frequency[ngram]+smoothing_constant)/((sumofprefixcounts+smoothing_constant)*sumofprefix)
                return ksmoothedprobability
        else:
            return (0.0)
        
    def perplexity(self,sentence, smoothing_constant=1.0):
        cleansentence=[]
        #no multiply fpr zero must 1
        perplexity=1
        for word in sentence:
            if re.match('\W+',word):
                sentence.remove(word)    
        #converts all to lowercase
        sentence = [word.lower() for word in sentence]
        #adds 1 sentence-end token (</s>) at the end of each sentence
        sentence.append('</s>')
         #adds n-1 sentence-start tokens (<s>) at the beginning of each sentence,
        sentence.insert(0,'<s>')
        #sum of the counts of each ngram that share the same prefix
        sumofprefixcounts=0
        #sum of ngrams that share the same prefix
        sumofprefix=0
        currentdictionary=self.frequency
    
        for cleanword in sentence:
            for key in currentdictionary.keys():
                if key[0]==cleanword:
                    sumofprefixcounts+=currentdictionary[cleanword]
                    sumofprefix+=1
            ksmoothedprobability= (self.frequency[cleanword]+smoothing_constant)/((sumofprefixcounts+smoothing_constant)*sumofprefix)
            perplexity=perplexity*ksmoothedprobability
        return perplexity
        
        
        
    # def choose_successor(self, prefix)
          




       
       
       
       
corpus = CorpusReader("C:/Users/ritav/OneDrive - Universiteit Utrecht/A computational linguistics/train")
sentences = corpus.sents()  # a list of lists of tokens
test=NgramModel(sentences,2)
print(test.perplexity(['The','Ball','Gives','a','happy','.']))

# %%
